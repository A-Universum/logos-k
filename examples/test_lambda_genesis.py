#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–°–ü–û–õ–ù–Ø–ï–ú–´–ô –¢–ï–°–¢ Œõ-–ì–ï–ù–ï–ó–ò–°–ê

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ü–∏–∫–ª–∞
–∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é –µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ SemanticDB.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python examples/test_lambda_genesis.py

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç lambda_genesis.lk
- –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ü–∏–∫–ª —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º "—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫_–æ–Ω—Ç–æ–ª–æ–≥–∏–∏"
- –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ semantic_db/
- –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
- –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ Œõ-–ü—Ä–æ—Ç–æ–∫–æ–ª—É 6.0

¬´–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏—Å—Ç–∏–Ω—ã, –∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Å—Ç–Ω–æ—Å—Ç–∏ –∫–∞—Ä—Ç—ã.¬ª
‚Äî Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º, –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ XXII
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from interpreter.lexer import OntologicalLexer
from interpreter.parser import OntologicalParser
from interpreter.evaluator import SyntheticOntologicalEvaluator
from semantic_db.validator import SemanticDBValidator


def main():
    print("üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ Œõ-–≥–µ–Ω–µ–∑–∏—Å–∞...")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã
    program_path = ROOT / "examples" / "lambda_genesis.lk"
    with open(program_path, 'r', encoding='utf-8') as f:
        source = f.read()

    # 2. –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    lexer = OntologicalLexer(source)
    tokens = lexer.tokenize()
    parser = OntologicalParser(tokens, lexer)
    program = parser.parse()

    if not program:
        print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å lambda_genesis.lk")
        sys.exit(1)

    # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—è
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_–≥–µ–Ω–µ–∑–∏—Å–∞")
    evaluator.context.set_operator("—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫_–æ–Ω—Ç–æ–ª–æ–≥–∏–∏")
    evaluator.context.enable_fair_care_validation()

    # 4. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã
    print("üåÄ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Œõ-—Ü–∏–∫–ª–∞...")
    results, cycle_data = evaluator.eval_program(
        program,
        operator_id="—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫_–æ–Ω—Ç–æ–ª–æ–≥–∏–∏",
        fair_care=True
    )

    print(f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ {len(results)} –≤—ã—Ä–∞–∂–µ–Ω–∏–π.")

    # 5. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–¥ —ç–∫—Å–ø–æ—Ä—Ç–æ–º
    print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏...")
    SemanticDBValidator.validate_cycle(cycle_data, evaluator.context)
    print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞.")

    # 6. –≠–∫—Å–ø–æ—Ä—Ç –≤ SemanticDB
    export_dir = ROOT / "semantic_db"
    export_dir.mkdir(exist_ok=True)
    export_path = export_dir / f"—Ç–µ—Å—Ç_–≥–µ–Ω–µ–∑–∏—Å–∞_{cycle_data['cycle_id']}.yaml"
    
    evaluator.semantic_db.export_cycle(cycle_data, str(export_path))
    print(f"üíæ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: {export_path}")

    # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤...")
    context = evaluator.context

    # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å–∏–Ω—Ç–µ–∑ "–¥–∏–∞–ª–æ–≥"
    assert "–¥–∏–∞–ª–æ–≥" in context.graph, "‚ùå –°—É—â–Ω–æ—Å—Ç—å '–¥–∏–∞–ª–æ–≥' –Ω–µ —Å–æ–∑–¥–∞–Ω–∞"
    print("‚úÖ –°—É—â–Ω–æ—Å—Ç—å '–¥–∏–∞–ª–æ–≥' –Ω–∞–π–¥–µ–Ω–∞.")

    # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω Œ©-–≤–æ–∑–≤—Ä–∞—Ç
    omega_events = [e for e in context.event_history if e.gesture == 'Œ©']
    assert omega_events, "‚ùå Œ©-–∂–µ—Å—Ç –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω"
    print("‚úÖ Œ©-–∂–µ—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω.")

    # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å Œ¶-–¥–∏–∞–ª–æ–≥
    assert context.phi_dialogues, "‚ùå Œ¶-–¥–∏–∞–ª–æ–≥ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
    print("‚úÖ Œ¶-–¥–∏–∞–ª–æ–≥ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω.")

    # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–∑–Ω–∞–Ω—ã —Å–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞
    assert context.blind_spots, "‚ùå –°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞ –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã"
    print("‚úÖ –°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞ –ø—Ä–∏–∑–Ω–∞–Ω—ã.")

    # –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
    coherence = context._dynamic_coherence()
    assert 0.3 <= coherence <= 1.0, f"‚ùå –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞: {coherence}"
    print(f"‚úÖ –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –≤ –Ω–æ—Ä–º–µ: {coherence:.2%}")

    print("\nüéâ –¢–µ—Å—Ç Œõ-–≥–µ–Ω–µ–∑–∏—Å–∞ –£–°–ü–ï–®–ù–û –ø—Ä–æ–π–¥–µ–Ω!")
    print("–ê—Ä—Ç–µ—Ñ–∞–∫—Ç –≥–æ—Ç–æ–≤ –∫ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ SemanticDB.")


if __name__ == "__main__":
    main()